{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latitude': -22.75, 'longitude': -45.625, 'generationtime_ms': 0.9059906005859375, 'utc_offset_seconds': -10800, 'timezone': 'America/Sao_Paulo', 'timezone_abbreviation': '-03', 'elevation': 1592.0, 'hourly_units': {'time': 'iso8601', 'temperature_2m': '°C'}, 'hourly': {'time': ['2024-11-22T00:00', '2024-11-22T01:00', '2024-11-22T02:00', '2024-11-22T03:00', '2024-11-22T04:00', '2024-11-22T05:00', '2024-11-22T06:00', '2024-11-22T07:00', '2024-11-22T08:00', '2024-11-22T09:00', '2024-11-22T10:00', '2024-11-22T11:00', '2024-11-22T12:00', '2024-11-22T13:00', '2024-11-22T14:00', '2024-11-22T15:00', '2024-11-22T16:00', '2024-11-22T17:00', '2024-11-22T18:00', '2024-11-22T19:00', '2024-11-22T20:00', '2024-11-22T21:00', '2024-11-22T22:00', '2024-11-22T23:00', '2024-11-23T00:00', '2024-11-23T01:00', '2024-11-23T02:00', '2024-11-23T03:00', '2024-11-23T04:00', '2024-11-23T05:00', '2024-11-23T06:00', '2024-11-23T07:00', '2024-11-23T08:00', '2024-11-23T09:00', '2024-11-23T10:00', '2024-11-23T11:00', '2024-11-23T12:00', '2024-11-23T13:00', '2024-11-23T14:00', '2024-11-23T15:00', '2024-11-23T16:00', '2024-11-23T17:00', '2024-11-23T18:00', '2024-11-23T19:00', '2024-11-23T20:00', '2024-11-23T21:00', '2024-11-23T22:00', '2024-11-23T23:00', '2024-11-24T00:00', '2024-11-24T01:00', '2024-11-24T02:00', '2024-11-24T03:00', '2024-11-24T04:00', '2024-11-24T05:00', '2024-11-24T06:00', '2024-11-24T07:00', '2024-11-24T08:00', '2024-11-24T09:00', '2024-11-24T10:00', '2024-11-24T11:00', '2024-11-24T12:00', '2024-11-24T13:00', '2024-11-24T14:00', '2024-11-24T15:00', '2024-11-24T16:00', '2024-11-24T17:00', '2024-11-24T18:00', '2024-11-24T19:00', '2024-11-24T20:00', '2024-11-24T21:00', '2024-11-24T22:00', '2024-11-24T23:00', '2024-11-25T00:00', '2024-11-25T01:00', '2024-11-25T02:00', '2024-11-25T03:00', '2024-11-25T04:00', '2024-11-25T05:00', '2024-11-25T06:00', '2024-11-25T07:00', '2024-11-25T08:00', '2024-11-25T09:00', '2024-11-25T10:00', '2024-11-25T11:00', '2024-11-25T12:00', '2024-11-25T13:00', '2024-11-25T14:00', '2024-11-25T15:00', '2024-11-25T16:00', '2024-11-25T17:00', '2024-11-25T18:00', '2024-11-25T19:00', '2024-11-25T20:00', '2024-11-25T21:00', '2024-11-25T22:00', '2024-11-25T23:00', '2024-11-26T00:00', '2024-11-26T01:00', '2024-11-26T02:00', '2024-11-26T03:00', '2024-11-26T04:00', '2024-11-26T05:00', '2024-11-26T06:00', '2024-11-26T07:00', '2024-11-26T08:00', '2024-11-26T09:00', '2024-11-26T10:00', '2024-11-26T11:00', '2024-11-26T12:00', '2024-11-26T13:00', '2024-11-26T14:00', '2024-11-26T15:00', '2024-11-26T16:00', '2024-11-26T17:00', '2024-11-26T18:00', '2024-11-26T19:00', '2024-11-26T20:00', '2024-11-26T21:00', '2024-11-26T22:00', '2024-11-26T23:00', '2024-11-27T00:00', '2024-11-27T01:00', '2024-11-27T02:00', '2024-11-27T03:00', '2024-11-27T04:00', '2024-11-27T05:00', '2024-11-27T06:00', '2024-11-27T07:00', '2024-11-27T08:00', '2024-11-27T09:00', '2024-11-27T10:00', '2024-11-27T11:00', '2024-11-27T12:00', '2024-11-27T13:00', '2024-11-27T14:00', '2024-11-27T15:00', '2024-11-27T16:00', '2024-11-27T17:00', '2024-11-27T18:00', '2024-11-27T19:00', '2024-11-27T20:00', '2024-11-27T21:00', '2024-11-27T22:00', '2024-11-27T23:00', '2024-11-28T00:00', '2024-11-28T01:00', '2024-11-28T02:00', '2024-11-28T03:00', '2024-11-28T04:00', '2024-11-28T05:00', '2024-11-28T06:00', '2024-11-28T07:00', '2024-11-28T08:00', '2024-11-28T09:00', '2024-11-28T10:00', '2024-11-28T11:00', '2024-11-28T12:00', '2024-11-28T13:00', '2024-11-28T14:00', '2024-11-28T15:00', '2024-11-28T16:00', '2024-11-28T17:00', '2024-11-28T18:00', '2024-11-28T19:00', '2024-11-28T20:00', '2024-11-28T21:00', '2024-11-28T22:00', '2024-11-28T23:00'], 'temperature_2m': [15.7, 15.6, 15.5, 14.9, 14.8, 14.7, 14.8, 15.7, 16.7, 17.1, 17.4, 16.8, 16.1, 15.9, 15.8, 16.1, 15.6, 15.3, 15.0, 14.8, 14.6, 14.3, 14.3, 14.2, 14.1, 14.1, 13.9, 13.7, 13.7, 13.4, 13.8, 14.7, 15.8, 16.8, 17.8, 17.8, 17.8, 17.9, 17.6, 17.3, 16.9, 15.9, 14.8, 14.0, 13.3, 12.8, 12.5, 12.4, 12.3, 12.1, 11.9, 11.2, 11.2, 11.0, 11.4, 12.9, 14.3, 15.3, 16.5, 17.3, 17.7, 18.4, 18.4, 18.4, 18.3, 17.6, 15.8, 14.0, 13.4, 13.2, 12.7, 12.5, 12.2, 11.9, 11.5, 11.0, 10.6, 10.5, 11.4, 14.2, 15.4, 16.5, 17.3, 18.7, 19.8, 20.7, 21.2, 20.9, 20.7, 20.1, 19.0, 17.0, 15.7, 15.4, 15.5, 15.4, 15.4, 15.5, 15.1, 14.3, 14.2, 13.8, 14.2, 15.9, 16.8, 17.7, 18.9, 20.2, 21.3, 21.8, 22.7, 23.1, 22.8, 22.2, 20.9, 18.9, 18.4, 18.9, 19.2, 19.0, 18.7, 18.0, 17.5, 15.7, 15.3, 15.2, 15.9, 18.8, 19.8, 20.0, 21.0, 22.2, 22.7, 23.5, 23.8, 24.5, 24.1, 23.8, 22.2, 19.8, 19.8, 19.2, 19.7, 19.1, 18.3, 17.3, 16.9, 16.4, 16.2, 16.5, 17.5, 20.5, 21.4, 22.1, 23.4, 24.5, 24.8, 25.6, 26.3, 26.1, 25.6, 24.2, 22.8, 20.7, 19.4, 17.7, 17.6, 17.4]}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "cidade = \"São Paulo\"\n",
    "url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "params = {\n",
    "    \"latitude\": -22.7386,\n",
    "    \"longitude\": -45.5921,\n",
    "    \"hourly\": \"temperature_2m\",  \n",
    "    \"timezone\": \"America/Sao_Paulo\",\n",
    "    \"past_days\":7,\n",
    "    \"forecast_days\":0\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(data)\n",
    "else:\n",
    "    print(f\"Erro na requisição: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "João\n",
      "25\n",
      "Rio de Janeiro\n",
      "{'nome': 'João', 'idade': 26, 'cidade': 'Rio de Janeiro', 'profissao': 'Engenheiro'}\n",
      "{\"nome\": \"João\", \"idade\": 26, \"cidade\": \"Rio de Janeiro\", \"profissao\": \"Engenheiro\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dados_json = '{\"nome\": \"João\", \"idade\": 25, \"cidade\": \"Rio de Janeiro\"}'\n",
    "dados_dicionario = json.loads(dados_json)\n",
    "\n",
    "print(dados_dicionario[\"nome\"])  \n",
    "print(dados_dicionario[\"idade\"])  \n",
    "print(dados_dicionario[\"cidade\"])  \n",
    "\n",
    "dados_dicionario[\"idade\"] = 26\n",
    "dados_dicionario[\"profissao\"] = \"Engenheiro\"\n",
    "\n",
    "print(dados_dicionario)  \n",
    "\n",
    "\n",
    "dados_json = json.dumps(dados_dicionario, ensure_ascii=False\n",
    ")\n",
    "print(dados_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro na requisição: HTTPSConnectionPool(host='site131323232.com', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000022234F7D1D0>: Failed to resolve 'site131323232.com' ([Errno 11001] getaddrinfo failed)\"))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.get(\"https://site131323232.com\")\n",
    "    response.raise_for_status()  # Lança exceção para códigos de status de erro\n",
    "except requests.exceptions.RequestException as erro:\n",
    "    print(f\"Erro na requisição: {erro}\")\n",
    "else:\n",
    "    print(\"Requisição bem-sucedida!\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endereço: Avenida Senador Salgado Filho, Lagoa Nova\n",
      "Cidade: Natal - RN\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "cep = \"59078900\"\n",
    "url = f\"https://viacep.com.br/ws/{cep}/json/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    dados_endereco = response.json()\n",
    "    print(f\"Endereço: {dados_endereco['logradouro']}, {dados_endereco['bairro']}\")\n",
    "    print(f\"Cidade: {dados_endereco['localidade']} - {dados_endereco['uf']}\")\n",
    "else:\n",
    "    print(f\"Erro ao consultar CEP: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Oi Fibra X Premium: internet mais rápida e tecnologia exclusiva (https://www.tecmundo.com.br/)\n",
      "- Veículos e tecnologia (https://olhardigital.com.br/)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "sites = [\n",
    "    \"https://www.tecmundo.com.br/\",\n",
    "    \"https://olhardigital.com.br/\",\n",
    "    \"https://canaltech.com.br/\",\n",
    "]\n",
    "\n",
    "palavras_chave = [\"tecnologia\", \"programação\", \"inteligência artificial\"]\n",
    "\n",
    "for site in sites:\n",
    "    response = requests.get(site)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    titulos = soup.find_all('h2') \n",
    "\n",
    "    \n",
    "    for titulo in titulos:\n",
    "        for palavra in palavras_chave:\n",
    "            if palavra.lower() in titulo.text.lower():\n",
    "                print(f\"- {titulo.text.strip()} ({site})\")\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "sites = [\n",
    "    \"https://www.tecmundo.com.br/\",\n",
    "    \"https://olhardigital.com.br/\",\n",
    "    \"https://canaltech.com.br/\",\n",
    "]\n",
    "\n",
    "palavras_chave = [\"tecnologia\", \"programação\", \"inteligência artificial\"]\n",
    "\n",
    "for site in sites:\n",
    "    response = requests.get(site)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    titulos = soup.find_all('h2') \n",
    "\n",
    "    \n",
    "    for titulo in titulos:\n",
    "        for palavra in palavras_chave:\n",
    "            if palavra.lower() in titulo.text.lower():\n",
    "                print(f\"- {titulo.text.strip()} ({site})\")\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
